{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunxi\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.393606\n",
      "Epoch: 2 \tTraining Loss: 0.101308\n",
      "Epoch: 3 \tTraining Loss: 0.074655\n",
      "Epoch: 4 \tTraining Loss: 0.058998\n",
      "Epoch: 5 \tTraining Loss: 0.051158\n",
      "Epoch: 6 \tTraining Loss: 0.043814\n",
      "Epoch: 7 \tTraining Loss: 0.038526\n",
      "Epoch: 8 \tTraining Loss: 0.034853\n",
      "Epoch: 9 \tTraining Loss: 0.030175\n",
      "Epoch: 10 \tTraining Loss: 0.026579\n",
      "model training takes 188.83246493339539 s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "torch.manual_seed(73)\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, hidden=64, output=10):\n",
    "        super(ConvNet, self).__init__()        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
    "        self.fc1 = torch.nn.Linear(256, 1024)\n",
    "        self.fc2 = torch.nn.Linear(1024, hidden)\n",
    "        self.fc3 = torch.nn.Linear(hidden, output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # the model uses the square activation function\n",
    "        x = x * x\n",
    "        # flattening while keeping the batch axis\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc1(x)\n",
    "        x = x * x\n",
    "        x = self.fc2(x)\n",
    "        x = x * x\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
    "    # model in training mode\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    \n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = ConvNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "model = train(model, train_loader, criterion, optimizer, 10)\n",
    "end = time.time()\n",
    "\n",
    "print(\"model training takes\",end - start,\"s\")\n",
    "\n",
    "# PATH = \"./mnist_cnn.pth\"\n",
    "# torch.save(model, PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.101917\n",
      "\n",
      "Test Accuracy of 0: 99% (971/980)\n",
      "Test Accuracy of 1: 98% (1117/1135)\n",
      "Test Accuracy of 2: 97% (1003/1032)\n",
      "Test Accuracy of 3: 99% (1000/1010)\n",
      "Test Accuracy of 4: 97% (962/982)\n",
      "Test Accuracy of 5: 97% (873/892)\n",
      "Test Accuracy of 6: 96% (921/958)\n",
      "Test Accuracy of 7: 94% (974/1028)\n",
      "Test Accuracy of 8: 97% (948/974)\n",
      "Test Accuracy of 9: 96% (978/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9747/10000)\n",
      "model testing takes 1.946789026260376 s\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, criterion):\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(len(target)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "        \n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss/len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ' \n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "\n",
    "start = time.time()\n",
    "test(model, test_loader, criterion)\n",
    "end = time.time()\n",
    "\n",
    "print(\"model testing takes\",end - start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
