{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CNN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-548b8c696f71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mCNN\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'CNN'"
     ]
    }
   ],
   "source": [
    "import tenseal as ts\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from CNN import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov2d takes 1.1100647449493408\n",
      "fc1 takes 8.285876750946045\n",
      "fc2 takes 0.6642599105834961\n",
      "cov2d takes 1.23469877243042\n",
      "fc1 takes 6.920460224151611\n",
      "fc2 takes 0.6263241767883301\n",
      "cov2d takes 0.9734354019165039\n",
      "fc1 takes 7.083643674850464\n",
      "fc2 takes 0.5894248485565186\n",
      "cov2d takes 1.019272804260254\n",
      "fc1 takes 7.719710111618042\n",
      "fc2 takes 0.6392905712127686\n",
      "cov2d takes 1.155907154083252\n",
      "fc1 takes 7.156893491744995\n",
      "fc2 takes 0.5784542560577393\n",
      "cov2d takes 0.9873592853546143\n",
      "fc1 takes 7.701486587524414\n",
      "fc2 takes 0.6253170967102051\n",
      "cov2d takes 1.0282502174377441\n",
      "fc1 takes 7.531859397888184\n",
      "fc2 takes 0.6667280197143555\n",
      "cov2d takes 1.2237255573272705\n",
      "fc1 takes 7.963705539703369\n",
      "fc2 takes 0.6921477317810059\n",
      "cov2d takes 1.1060433387756348\n",
      "fc1 takes 8.542125463485718\n",
      "fc2 takes 0.7679455280303955\n",
      "cov2d takes 1.7145001888275146\n",
      "fc1 takes 9.173471450805664\n",
      "fc2 takes 1.0970730781555176\n",
      "cov2d takes 1.4361958503723145\n",
      "fc1 takes 10.126958847045898\n",
      "fc2 takes 1.0042812824249268\n",
      "cov2d takes 1.5558669567108154\n",
      "fc1 takes 9.439756870269775\n",
      "fc2 takes 0.7150847911834717\n",
      "cov2d takes 1.2067458629608154\n",
      "fc1 takes 7.760209321975708\n",
      "fc2 takes 0.6631906032562256\n",
      "cov2d takes 1.0432069301605225\n",
      "fc1 takes 6.692103385925293\n",
      "fc2 takes 0.5834383964538574\n",
      "cov2d takes 0.9434776306152344\n",
      "fc1 takes 6.321101903915405\n",
      "fc2 takes 0.5435140132904053\n",
      "cov2d takes 0.927513599395752\n",
      "fc1 takes 5.695770263671875\n",
      "fc2 takes 0.5565071105957031\n",
      "cov2d takes 0.867678165435791\n",
      "fc1 takes 5.961061239242554\n",
      "fc2 takes 0.5425481796264648\n",
      "cov2d takes 0.8746423721313477\n",
      "fc1 takes 5.990005016326904\n",
      "fc2 takes 0.5764219760894775\n",
      "cov2d takes 0.8886229991912842\n",
      "fc1 takes 6.465744733810425\n",
      "fc2 takes 0.5684347152709961\n",
      "cov2d takes 0.9544515609741211\n",
      "fc1 takes 6.214385986328125\n",
      "fc2 takes 0.6073739528656006\n",
      "cov2d takes 0.9594323635101318\n",
      "fc1 takes 6.841709136962891\n",
      "fc2 takes 0.6303064823150635\n",
      "cov2d takes 1.012294054031372\n",
      "fc1 takes 6.9344565868377686\n",
      "fc2 takes 0.6432788372039795\n",
      "cov2d takes 1.053184986114502\n",
      "fc1 takes 7.550846815109253\n",
      "fc2 takes 0.6861658096313477\n",
      "cov2d takes 1.1319341659545898\n",
      "fc1 takes 7.8150670528411865\n",
      "fc2 takes 0.7390587329864502\n",
      "cov2d takes 1.390289306640625\n",
      "fc1 takes 8.712663650512695\n",
      "fc2 takes 0.8087983131408691\n",
      "cov2d takes 1.328449010848999\n",
      "fc1 takes 12.898199081420898\n",
      "fc2 takes 1.125992774963379\n",
      "cov2d takes 1.627643346786499\n",
      "fc1 takes 11.08087706565857\n",
      "fc2 takes 0.7340846061706543\n",
      "cov2d takes 1.2047786712646484\n",
      "fc1 takes 7.423149824142456\n",
      "fc2 takes 0.6213371753692627\n",
      "cov2d takes 0.9804127216339111\n",
      "fc1 takes 6.346033573150635\n",
      "fc2 takes 0.5555148124694824\n",
      "cov2d takes 0.9235286712646484\n",
      "fc1 takes 6.279209852218628\n",
      "fc2 takes 0.6462705135345459\n",
      "cov2d takes 0.9943089485168457\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b702cc2e1cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[0menc_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncConvNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m \u001b[0menc_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model testing takes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b702cc2e1cc2>\u001b[0m in \u001b[0;36menc_test\u001b[1;34m(context, model, test_loader, criterion, kernel_shape, stride)\u001b[0m\n\u001b[0;32m     90\u001b[0m         )\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# Encrypted evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0menc_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindows_nb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;31m# Decryption of result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b702cc2e1cc2>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-b702cc2e1cc2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, enc_x, windows_nb)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# fc1 layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0menc_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1_weight\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1_bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fc1 takes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tenseal\\tensors\\ckksvector.py\u001b[0m in \u001b[0;36mmm\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"CKKSVector\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"CKKSVector\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tenseal\\tensors\\abstract_tensor.py\u001b[0m in \u001b[0;36m_wrap\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"AbstractTensor\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;34m\"\"\"Return a new tensor object wrapping the low level tensor object\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "It's a PyTorch-like model using operations implemented in TenSEAL.\n",
    "    - .mm() method is doing the vector-matrix multiplication explained above.\n",
    "    - you can use + operator to add a plain vector as a bias.\n",
    "    - .conv2d_im2col() method is doing a single convlution operation.\n",
    "    - .square_() just square the encrypted vector inplace.\n",
    "\"\"\"\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, hidden=64, output=10):\n",
    "        super(ConvNet, self).__init__()        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
    "        self.fc1 = torch.nn.Linear(256, hidden)\n",
    "        self.fc2 = torch.nn.Linear(hidden, output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # the model uses the square activation function\n",
    "        x = x * x\n",
    "        # flattening while keeping the batch axis\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc1(x)\n",
    "        x = x * x\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "class EncConvNet:\n",
    "    def __init__(self, torch_nn):\n",
    "        self.conv1_weight = torch_nn.conv1.weight.data.view(\n",
    "            torch_nn.conv1.out_channels, torch_nn.conv1.kernel_size[0],\n",
    "            torch_nn.conv1.kernel_size[1]\n",
    "        ).tolist()\n",
    "        self.conv1_bias = torch_nn.conv1.bias.data.tolist()\n",
    "        \n",
    "        self.fc1_weight = torch_nn.fc1.weight.T.data.tolist()\n",
    "        self.fc1_bias = torch_nn.fc1.bias.data.tolist()\n",
    "        \n",
    "        self.fc2_weight = torch_nn.fc2.weight.T.data.tolist()\n",
    "        self.fc2_bias = torch_nn.fc2.bias.data.tolist()\n",
    "        \n",
    "        \n",
    "    def forward(self, enc_x, windows_nb):\n",
    "        # conv layer\n",
    "        start = time.time()\n",
    "        enc_channels = []\n",
    "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
    "            y = enc_x.conv2d_im2col(kernel, windows_nb) + bias\n",
    "            enc_channels.append(y)\n",
    "        end = time.time()\n",
    "        print(\"cov2d takes\", end - start)\n",
    "        \n",
    "        \n",
    "        # pack all channels into a single flattened vector\n",
    "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        # square activation\n",
    "        enc_x.square_()\n",
    "        # fc1 layer\n",
    "        start = time.time()\n",
    "        enc_x = enc_x.mm(self.fc1_weight) + self.fc1_bias\n",
    "        end = time.time()\n",
    "        print(\"fc1 takes\", end - start)\n",
    "        # square activation\n",
    "        enc_x.square_()\n",
    "        # fc2 layer\n",
    "        start = time.time()\n",
    "        enc_x = enc_x.mm(self.fc2_weight) + self.fc2_bias\n",
    "        end = time.time()\n",
    "        print(\"fc2 takes\", end - start)\n",
    "        return enc_x\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    \n",
    "def enc_test(context, model, test_loader, criterion, kernel_shape, stride):\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    \n",
    "    cnt = 0\n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        # Encoding and encryption\n",
    "        x_enc, windows_nb = ts.im2col_encoding(\n",
    "            context, data.view(28, 28).tolist(), kernel_shape[0],\n",
    "            kernel_shape[1], stride\n",
    "        )\n",
    "        # Encrypted evaluation\n",
    "        enc_output = enc_model(x_enc, windows_nb)\n",
    "        # Decryption of result\n",
    "        output = enc_output.decrypt()\n",
    "        output = torch.tensor(output).view(1, -1)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "        # calculate test accuracy for each object class\n",
    "        label = target.data[0]\n",
    "        class_correct[label] += correct.item()\n",
    "        class_total[label] += 1\n",
    "        cnt += 1\n",
    "        if cnt == 100:\n",
    "            break\n",
    "\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss / sum(class_total)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "    \n",
    "    print(class_correct)\n",
    "    print(class_total)\n",
    "\n",
    "\n",
    "\n",
    "# Load one element at a time\n",
    "model = torch.load(\"mnist_cnn.pth\")\n",
    "model.eval()\n",
    "\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "batch_size = 64\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "# required for encoding\n",
    "kernel_shape = model.conv1.kernel_size\n",
    "stride = model.conv1.stride[0]\n",
    "\n",
    "\n",
    "## Encryption Parameters\n",
    "\n",
    "# controls precision of the fractional part\n",
    "bits_scale = 26\n",
    "\n",
    "# Create TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
    ")\n",
    "\n",
    "# set the scale\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "\n",
    "# galois keys are required to do ciphertext rotations\n",
    "context.generate_galois_keys()\n",
    "\n",
    "\n",
    "# enc_model = EncConvNet(model)\n",
    "enc_model = EncConvNet(model)\n",
    "start = time.time()\n",
    "enc_test(context, enc_model, test_loader, criterion, kernel_shape, stride)\n",
    "end = time.time()\n",
    "print(\"model testing takes\",end - start,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
